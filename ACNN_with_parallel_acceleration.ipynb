{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#environment import\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, Callback\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#GPU quota\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACNN model\n",
    "class ACNN(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ACNN, self).__init__(**kwargs)\n",
    "        \"\"\"model initialize\"\"\"\n",
    "\n",
    "        #digital layers initialise\n",
    "        self.batchnomalization_1 = layers.BatchNormalization()\n",
    "        self.batchnomalization_2 = layers.BatchNormalization()\n",
    "        self.maxpooling_1 = layers.MaxPooling2D((3,3))\n",
    "        self.maxpooling_2 = layers.MaxPooling2D((2,2))\n",
    "        self.activation_1 = layers.Activation('relu')\n",
    "        self.conv_1 = layers.Conv2D(64,(3,3),activation='relu')\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dropout = layers.Dropout(0.4)\n",
    "        self.dense1 = layers.Dense(256, activation='relu')\n",
    "        self.dense2 = layers.Dense(84, activation='relu')\n",
    "        self.dense3 = layers.Dense(10, activation='softmax')\n",
    "        \n",
    "        #optical parameters initialise\n",
    "        self.size=84        #number of samples of the training phase\n",
    "        self.kernel_num=16  #number of the optical kernel\n",
    "        self.size_f=167     #number of samples in the spatial frequency domain\n",
    "        self.P_pad=np.int32(((self.size_f+1)/2-self.size)/2)    #put pupil function in the periphery to fill 0 to self.size_f when doing Autocorrelation\n",
    "        self.X_size=90      #resize input images\n",
    "        self.X_pad=np.int32((self.size_f+1-self.X_size)/2)      #put resized input images in the periphery to fill 0 to self.size_f befering FFT\n",
    "        self.center=120     #take the image center after optical convolution\n",
    "\n",
    "        #pupil function initialise\n",
    "        self.ran = np.random.uniform(-0.5*np.pi, 0.5*np.pi, [self.kernel_num, 15, 15])\n",
    "        self.ran=tf.expand_dims(self.ran,axis=-1)\n",
    "        self.ran=tf.image.resize(self.ran,[self.size,self.size])\n",
    "        self.ran=tf.squeeze(self.ran)\n",
    "        self.P = tf.Variable(self.ran,trainable=True,name='P',dtype=tf.float32)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"model propagation\"\"\"\n",
    "\n",
    "        #FFT for inputs\n",
    "        x = inputs\n",
    "        x = tf.image.resize(x, (self.X_size, self.X_size))\n",
    "        x = tf.pad(x, [[0,0],[self.X_pad, self.X_pad-1], [self.X_pad, self.X_pad-1],[0,0]], mode='CONSTANT')\n",
    "        x = tf.squeeze(x, axis=-1)\n",
    "        x = tf.cast(x, tf.complex64)\n",
    "\n",
    "        x=tf.signal.fftshift(x)\n",
    "        x=tf.signal.fft2d(x)\n",
    "        x=tf.signal.fftshift(x)\n",
    "        \n",
    "        #optical convolution with parallel acceleration\n",
    "        #paralled calculation\n",
    "        x = tf.repeat(x, 16, axis=0)\n",
    "\n",
    "        x, OTF = self.popagation(x, self.P)\n",
    "        x = tf.math.real(x)\n",
    "        # Split into 16 tensors of shape 16*167*167 along the first dimension\n",
    "        split_tensor = tf.split(x, 16, axis=0)\n",
    "\n",
    "        # Initialize an empty list to store results\n",
    "        result = []\n",
    "\n",
    "        # Operate on each 16*167*167 tensor\n",
    "        for tensor in split_tensor:\n",
    "            # Split the 16*167*167 tensor into two 8*167*167 tensors\n",
    "            sub_tensors = tf.split(tensor, 2, axis=0)\n",
    "            \n",
    "            # Subtract the two tensors to get an 8*167*167 image\n",
    "            sub_result = tf.subtract(sub_tensors[0], sub_tensors[1])\n",
    "            \n",
    "            # Transpose the 8*167*167 tensor to 167*167*8\n",
    "            transposed_result = tf.transpose(sub_result, perm=[1, 2, 0])\n",
    "            \n",
    "            # Add the result to the result list\n",
    "            result.append(transposed_result)\n",
    "\n",
    "        # Stack the 16 resulting 167*167*8 images into a tensor of shape 16*167*167*8\n",
    "        x = tf.stack(result, axis=0)\n",
    "\n",
    "        noise_factor = 0.003\n",
    "        x = x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x.shape)\n",
    "\n",
    "        #digital backend\n",
    "        x = self.get_center(x)\n",
    "        x = self.activation_1(x)\n",
    "        x = self.maxpooling_1(x)\n",
    "        #x = self.conv_1(x)\n",
    "        #x = self.maxpooling_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        #x = self.dense1(x)\n",
    "        #x = self.batchnomalization_1(x)\n",
    "        #x = self.dense2(x)\n",
    "        #x = self.batchnomalization_2(x)\n",
    "        outputs = self.dense3(x)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def Acorr(self,P):\n",
    "        \"\"\"Autocorrelation calculation without FFT acceleration\"\"\"\n",
    "        \n",
    "        #size preparation\n",
    "        PP=tf.math.conj(P)\n",
    "\n",
    "        X=self.size+2*self.P_pad\n",
    "        padx=np.int32(X/2)\n",
    "        pady=np.int32(X/2)\n",
    "        P = tf.pad(P, [[padx, padx-1], [pady, padx-1]], mode='CONSTANT')\n",
    "        PP = tf.pad(PP, [[padx, padx-1], [pady, padx-1]], mode='CONSTANT')\n",
    "        P = tf.expand_dims(tf.expand_dims(P,axis=0),axis=3)\n",
    "        PP = tf.expand_dims(tf.expand_dims(PP,axis=2),axis=3)\n",
    "\n",
    "        #convolution of self and self-conjugation\n",
    "        P_real = tf.math.real(P)\n",
    "        P_imag = tf.math.imag(P)\n",
    "        PP_real = tf.math.real(PP)\n",
    "        PP_imag = tf.math.imag(PP)\n",
    "\n",
    "        strides=[1,1,1,1]\n",
    "        padding='SAME'\n",
    "        OTF_real = tf.nn.conv2d(P_real, PP_real, strides, padding) - tf.nn.conv2d(P_imag, PP_imag, strides, padding)\n",
    "        OTF_imag = tf.nn.conv2d(P_real, PP_imag, strides, padding) + tf.nn.conv2d(P_imag, PP_real, strides, padding)\n",
    "\n",
    "        #normalization\n",
    "        P_amp = self.get_amp(self.size,self.size/2)\n",
    "        amp=tf.reduce_sum(tf.math.abs(P_amp) ** 2)\n",
    "        OTF_real=OTF_real/amp\n",
    "        OTF_imag=OTF_imag/amp\n",
    "        OTF = tf.complex(OTF_real, OTF_imag)\n",
    "        OTF = tf.squeeze(OTF)\n",
    "\n",
    "        return OTF\n",
    "    \n",
    "    def FFT_Acorr(self,P):\n",
    "        \"\"\"Autocorrelation calculation with FFT acceleration\"\"\"\n",
    "\n",
    "        #size preparation\n",
    "        X=self.size+2*self.P_pad\n",
    "        padx=np.int32(X/2)\n",
    "        pady=np.int32(X/2)\n",
    "        P = tf.pad(P, [[0,0],[padx, padx-1], [pady, padx-1]], mode='CONSTANT')\n",
    "\n",
    "        #FFT acceleration\n",
    "        F_P=tf.signal.fft2d(P)\n",
    "        F_PP=tf.math.conj(F_P)\n",
    "        F_OTF=tf.multiply(F_P,F_PP)\n",
    "        OTF = tf.signal.ifft2d(F_OTF) \n",
    "        OTF = tf.signal.fftshift(OTF)\n",
    "        OTF_1, OTF_2 = tf.split(OTF, num_or_size_splits=2, axis=0)\n",
    "        OTF = tf.concat([OTF_2, OTF_1], axis=0)\n",
    "                \n",
    "        #normalization\n",
    "        P_amp = self.get_amp(self.size,self.size/2)\n",
    "        amp=tf.reduce_sum(tf.math.abs(P_amp) ** 2)\n",
    "        OTF_real = tf.math.real(OTF)\n",
    "        OTF_imag = tf.math.imag(OTF)\n",
    "        OTF_real=OTF_real/amp\n",
    "        OTF_imag=OTF_imag/amp\n",
    "        OTF = tf.complex(OTF_real, OTF_imag)\n",
    "\n",
    "        return OTF \n",
    "    def get_amp(self,M,R):\n",
    "        \"\"\"get a central with a value of 1, surrounded by a distribution of 0\"\"\"\n",
    "\n",
    "        arr = np.zeros((M, M))\n",
    "        imgSize = M\n",
    "        x, y = np.meshgrid(np.arange(-(imgSize-1)/2, (imgSize)/2), np.arange(-(imgSize-1)/2, (imgSize)/2))\n",
    "        arr[x**2 + y**2 <= R**2] = 1\n",
    "        arr=tf.cast(arr,tf.float32)\n",
    "        tensor = tf.convert_to_tensor(arr)\n",
    "\n",
    "        return tensor\n",
    "    \n",
    "    def get_center(self,input_tensor):\n",
    "        \"\"\"cut part of the image center\"\"\"\n",
    "\n",
    "        center=self.center\n",
    "        b=np.int32((self.size_f+1)/2-0.5*center)\n",
    "        begin = [0, b, b, 0]\n",
    "        size = [16, center, center, 8]\n",
    "        output_tensor = tf.slice(input_tensor, begin, size)\n",
    "        return output_tensor\n",
    "\n",
    "    def popagation(self,x,phase):\n",
    "        \"\"\"optical propagation in the spatial frequency domain\"\"\"\n",
    "        \n",
    "        #pupil function preparation\n",
    "        P_amp = self.get_amp(self.size,self.size/2)\n",
    "        P_amp = tf.expand_dims(P_amp,axis=0)\n",
    "        P_amp=tf.repeat(P_amp,16,axis=0)\n",
    "        P_real=P_amp * tf.cos(phase)\n",
    "        P_real=tf.pad(P_real,[[0,0], [self.P_pad,self.P_pad],[self.P_pad,self.P_pad]],mode='CONSTANT')\n",
    "        P_imag=P_amp * tf.sin(phase)\n",
    "        P_imag=tf.pad(P_imag,[[0,0], [self.P_pad,self.P_pad],[self.P_pad,self.P_pad]],mode='CONSTANT')\n",
    "        P = tf.complex(P_real, P_imag)\n",
    "\n",
    "        #Acorr\n",
    "        OTF=self.FFT_Acorr(P)\n",
    "\n",
    "        #size fit\n",
    "        OTF_0 = OTF\n",
    "        for i in range(15):\n",
    "            OTF = tf.concat([OTF, OTF_0], axis=0)\n",
    "\n",
    "        #multiplication in the spatial frequency domain\n",
    "        x = tf.multiply(x,OTF)\n",
    "        \n",
    "        #IFFT\n",
    "        x=tf.signal.fftshift(x)\n",
    "        x=tf.signal.ifft2d(x)\n",
    "        x=tf.signal.fftshift(x)\n",
    "\n",
    "        return x,OTF_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial learning rate\n",
    "initial_learning_rate = 1e-2\n",
    "\n",
    "# Set attenuation steps and attenuation rate\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.95\n",
    "\n",
    "# Create learning rate decay strategy\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate)\n",
    "\n",
    "# Create optimizer instance\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model_P1 = ACNN()\n",
    "model_P1.build((None, 28, 28, 1))\n",
    "model_P1.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# dataset import\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "#(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "x_train = tf.expand_dims(x_train, axis=-1)\n",
    "x_test = tf.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Define noise factor\n",
    "noise_factor = 0.04\n",
    "\n",
    "# Add Gaussian noise\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "# Ensure data is between 0 and 1\n",
    "x_train = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "def augment(images, labels, x1=0.01, x2=0.1, x3=0.05):\n",
    "    # Random rotation\n",
    "    rotation_layer = tf.keras.layers.experimental.preprocessing.RandomRotation(factor=(-x1, x1), fill_mode='reflect', interpolation='bilinear')\n",
    "    images = rotation_layer(images)\n",
    "    \n",
    "    # Random zoom\n",
    "    zoom_layer = tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=(-x2, x2), width_factor=(-x2, x2), fill_mode='reflect', interpolation='bilinear')\n",
    "    images = zoom_layer(images)\n",
    "    \n",
    "    # Random horizontal and vertical translation\n",
    "    translation_layer = tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=(-x3, x3), width_factor=(-x3, x3), fill_mode='reflect', interpolation='bilinear')\n",
    "    images = translation_layer(images)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Create dataset and set batch size\n",
    "BATCH_SIZE = 16\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.map(augment).shuffle(10000).batch(BATCH_SIZE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')  # Create CSVLogger object, logs will be saved to a file named 'training.log'\n",
    "\n",
    "class SaveBestModelVariables(Callback):\n",
    "    def __init__(self, filepath, monitor='val_accuracy', mode='max'):\n",
    "        super(SaveBestModelVariables, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.best = -float('inf') if mode == 'max' else float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is not None:\n",
    "            if (self.mode == 'max' and current > self.best) or (self.mode == 'min' and current < self.best):\n",
    "                self.best = current\n",
    "                trainable_variables = self.model.trainable_variables\n",
    "                # Set font and font size设置字体和字号\n",
    "                plt.rcParams['font.family'] = 'Arial'\n",
    "                plt.rcParams['font.size'] = 20  \n",
    "\n",
    "                # Use the model to make predictions\n",
    "                y_pred = model_P1.predict(x_test, batch_size=16)\n",
    "\n",
    "                # Convert prediction results to class labels\n",
    "                y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "                # Calculate confusion matrix\n",
    "                confusion_mtx = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "                # Plot confusion matrix using seaborn\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap=plt.cm.Blues) \n",
    "                plt.xlabel('Predicted label')\n",
    "                plt.ylabel('True label')\n",
    "\n",
    "                # Save the image\n",
    "                plt.savefig('confusion_matrix_cifar10_all.pdf')\n",
    "                with open(self.filepath, 'wb') as f:\n",
    "                    pickle.dump(trainable_variables, f)\n",
    "                print(f\"Epoch {epoch + 1}: {self.monitor} improved to {current}, saving model variables to {self.filepath}\")\n",
    "\n",
    "# Create custom callback function\n",
    "save_best_model_variables = SaveBestModelVariables(filepath='best_model_variables.pkl', monitor='val_accuracy', mode='max')\n",
    "\n",
    "#training without data qugumation\n",
    "model_P1.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=40, batch_size=16, callbacks=[csv_logger, save_best_model_variables])\n",
    "#training with data qugumation\n",
    "#model_P1.fit(train_ds, validation_data=test_ds,epochs=40, batch_size=16, callbacks=[csv_logger, save_best_model_variables])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
