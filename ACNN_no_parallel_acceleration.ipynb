{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#environment import\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, Callback\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#GPU quota\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACNN model\n",
    "class ACNN(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ACNN, self).__init__(**kwargs)\n",
    "        \"\"\"model initialize\"\"\"\n",
    "\n",
    "        #digital layers initialise\n",
    "        self.batchnomalization_1 = layers.BatchNormalization()\n",
    "        self.batchnomalization_2 = layers.BatchNormalization()\n",
    "        self.maxpooling_1 = layers.MaxPooling2D((3,3))\n",
    "        self.maxpooling_2 = layers.MaxPooling2D((2,2))\n",
    "        self.activation_1 = layers.Activation('relu')\n",
    "        self.conv_1 = layers.Conv2D(64,(3,3),activation='relu')\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dropout = layers.Dropout(0.4)\n",
    "        self.dense1 = layers.Dense(256, activation='relu')\n",
    "        self.dense2 = layers.Dense(84, activation='relu')\n",
    "        self.dense3 = layers.Dense(10, activation='softmax')\n",
    "        \n",
    "        #optical parameters initialise\n",
    "        self.size=84        #number of samples of the training phase\n",
    "        self.kernel_num=16  #number of the optical kernel\n",
    "        self.size_f=167     #number of samples in the spatial frequency domain\n",
    "        self.P_pad=np.int32(((self.size_f+1)/2-self.size)/2)    #put pupil function in the periphery to fill 0 to self.size_f when doing Autocorrelation\n",
    "        self.X_size=90      #resize input images\n",
    "        self.X_pad=np.int32((self.size_f+1-self.X_size)/2)      #put resized input images in the periphery to fill 0 to self.size_f befering FFT\n",
    "        self.center=120     #take the image center after optical convolution\n",
    "\n",
    "        #pupil function initialise\n",
    "        self.ran = np.random.uniform(-0.5*np.pi, 0.5*np.pi, [self.kernel_num, 15, 15])\n",
    "        self.ran=tf.expand_dims(self.ran,axis=-1)\n",
    "        self.ran=tf.image.resize(self.ran,[self.size,self.size])\n",
    "        self.ran=tf.squeeze(self.ran)\n",
    "        self.P = tf.Variable(self.ran,trainable=True,name='P',dtype=tf.float32)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"model propagation\"\"\"\n",
    "\n",
    "        #FFT for inputs\n",
    "        x = inputs\n",
    "        x = tf.image.rgb_to_grayscale(x)\n",
    "        x = tf.image.resize(x, (self.X_size, self.X_size))\n",
    "        x = tf.pad(x, [[0,0],[self.X_pad, self.X_pad-1], [self.X_pad, self.X_pad-1],[0,0]], mode='CONSTANT')\n",
    "        x = tf.squeeze(x, axis=-1)\n",
    "        x = tf.cast(x, tf.complex64)\n",
    "\n",
    "        x=tf.signal.fftshift(x)\n",
    "        x=tf.signal.fft2d(x)\n",
    "        x=tf.signal.fftshift(x)\n",
    "\n",
    "        #optical convolution without parallel acceleration\n",
    "        for i in range(np.int32(self.kernel_num/2)):\n",
    "            [x1,OTF1]=self.propagation(x,self.P[2*i])\n",
    "            x1=tf.math.real(x1)\n",
    "            [x2,OTF2]=self.propagation(x,self.P[2*i+1])\n",
    "            x2=tf.math.real(x2)\n",
    "            if i==0:\n",
    "                x_1 = tf.expand_dims(x1, axis=-1)\n",
    "                OTF_1 = tf.expand_dims(OTF1, axis=-1)\n",
    "                x_2 = tf.expand_dims(x2, axis=-1)\n",
    "                OTF_2 = tf.expand_dims(OTF2, axis=-1)\n",
    "            else:\n",
    "                x_11 = tf.expand_dims(x1, axis=-1)\n",
    "                OTF_11 = tf.expand_dims(OTF1, axis=-1)\n",
    "                x_22 = tf.expand_dims(x2, axis=-1)\n",
    "                OTF_22 = tf.expand_dims(OTF2, axis=-1)\n",
    "                \n",
    "                x_1 = tf.concat([x_1, x_11], axis=-1)\n",
    "                OTF_1 = tf.concat([OTF_1, OTF_11], axis=-1)\n",
    "                x_2 = tf.concat([x_2, x_22], axis=-1)\n",
    "                OTF_2 = tf.concat([OTF_2, OTF_22], axis=-1)\n",
    "\n",
    "        noise_factor = 0.003\n",
    "        x_1 = x_1 + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_1.shape)\n",
    "        x_2= x_2 + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_2.shape)\n",
    "\n",
    "        #digital backend\n",
    "        x = x_1-x_2\n",
    "        x = self.get_center(x)\n",
    "        x = self.activation_1(x)\n",
    "        x = self.maxpooling_1(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.maxpooling_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.batchnomalization_1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.batchnomalization_2(x)\n",
    "        outputs = self.dense3(x)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def Acorr(self,P):\n",
    "        \"\"\"Autocorrelation calculation without FFT acceleration\"\"\"\n",
    "        \n",
    "        #size preparation\n",
    "        PP=tf.math.conj(P)\n",
    "\n",
    "        X=self.size+2*self.P_pad\n",
    "        padx=np.int32(X/2)\n",
    "        pady=np.int32(X/2)\n",
    "        P = tf.pad(P, [[padx, padx-1], [pady, padx-1]], mode='CONSTANT')\n",
    "        PP = tf.pad(PP, [[padx, padx-1], [pady, padx-1]], mode='CONSTANT')\n",
    "        P = tf.expand_dims(tf.expand_dims(P,axis=0),axis=3)\n",
    "        PP = tf.expand_dims(tf.expand_dims(PP,axis=2),axis=3)\n",
    "\n",
    "        #convolution of self and self-conjugation\n",
    "        P_real = tf.math.real(P)\n",
    "        P_imag = tf.math.imag(P)\n",
    "        PP_real = tf.math.real(PP)\n",
    "        PP_imag = tf.math.imag(PP)\n",
    "\n",
    "        strides=[1,1,1,1]\n",
    "        padding='SAME'\n",
    "        OTF_real = tf.nn.conv2d(P_real, PP_real, strides, padding) - tf.nn.conv2d(P_imag, PP_imag, strides, padding)\n",
    "        OTF_imag = tf.nn.conv2d(P_real, PP_imag, strides, padding) + tf.nn.conv2d(P_imag, PP_real, strides, padding)\n",
    "\n",
    "        #normalization\n",
    "        P_amp = self.get_amp(self.size,self.size/2)\n",
    "        amp=tf.reduce_sum(tf.math.abs(P_amp) ** 2)\n",
    "        OTF_real=OTF_real/amp\n",
    "        OTF_imag=OTF_imag/amp\n",
    "        OTF = tf.complex(OTF_real, OTF_imag)\n",
    "        OTF = tf.squeeze(OTF)\n",
    "\n",
    "        return OTF\n",
    "    \n",
    "    def FFT_Acorr(self,P):\n",
    "        \"\"\"Autocorrelation calculation with FFT acceleration\"\"\"\n",
    "\n",
    "        #size preparation\n",
    "        X=self.size+2*self.P_pad\n",
    "        padx=np.int32(X/2)\n",
    "        pady=np.int32(X/2)\n",
    "        P = tf.pad(P, [[padx, padx-1], [pady, padx-1]], mode='CONSTANT')\n",
    "        \n",
    "        #FFT acceleration\n",
    "        F_P=tf.signal.fft2d(P)\n",
    "        F_PP=tf.math.conj(F_P)\n",
    "        F_OTF=tf.multiply(F_P,F_PP)\n",
    "        OTF = tf.signal.ifft2d(F_OTF) \n",
    "        OTF = tf.signal.fftshift(OTF)\n",
    "        \n",
    "        #normalization\n",
    "        P_amp = self.get_amp(self.size,self.size/2)\n",
    "        amp=tf.reduce_sum(tf.math.abs(P_amp) ** 2)\n",
    "        OTF_real = tf.math.real(OTF)\n",
    "        OTF_imag = tf.math.imag(OTF)\n",
    "        OTF_real=OTF_real/amp\n",
    "        OTF_imag=OTF_imag/amp\n",
    "        OTF = tf.complex(OTF_real, OTF_imag)\n",
    "\n",
    "        return OTF\n",
    "\n",
    "    def get_amp(self,M,R):\n",
    "        \"\"\"get a central with a value of 1, surrounded by a distribution of 0\"\"\"\n",
    "\n",
    "        arr = np.zeros((M, M))\n",
    "        imgSize = M\n",
    "        x, y = np.meshgrid(np.arange(-(imgSize-1)/2, (imgSize)/2), np.arange(-(imgSize-1)/2, (imgSize)/2))\n",
    "        arr[x**2 + y**2 <= R**2] = 1\n",
    "        arr=tf.cast(arr,tf.float32)\n",
    "        tensor = tf.convert_to_tensor(arr)\n",
    "\n",
    "        return tensor\n",
    "    \n",
    "    def get_center(self,input_tensor):\n",
    "        \"\"\"cut part of the image center\"\"\"\n",
    "\n",
    "        center=self.center\n",
    "        b=np.int32((self.size_f+1)/2-0.5*center)\n",
    "        begin = [0, b, b, 0]\n",
    "        size = [16, center, center, 8]\n",
    "        output_tensor = tf.slice(input_tensor, begin, size)\n",
    "        return output_tensor\n",
    "\n",
    "    def propagation(self,x,phase):\n",
    "        \"\"\"optical propagation in the spatial frequency domain\"\"\"\n",
    "\n",
    "        #pupil function preparation\n",
    "        P_amp = self.get_amp(self.size,self.size/2)\n",
    "        P_real=P_amp * tf.cos(phase)\n",
    "        P_real=tf.pad(P_real,[[self.P_pad,self.P_pad],[self.P_pad,self.P_pad]],mode='CONSTANT')\n",
    "        P_imag=P_amp * tf.sin(phase)\n",
    "        P_imag=tf.pad(P_imag,[[self.P_pad,self.P_pad],[self.P_pad,self.P_pad]],mode='CONSTANT')\n",
    "        P = tf.complex(P_real, P_imag)\n",
    "\n",
    "        #Acorr\n",
    "        OTF=self.FFT_Acorr(P)\n",
    "\n",
    "        #repeat OTF to fit the batchsize=16\n",
    "        OTF_real = tf.math.real(OTF)\n",
    "        OTF_imag = tf.math.imag(OTF)\n",
    "        OTF_real=tf.reshape(OTF_real,[1,self.size_f,self.size_f])\n",
    "        OTF_imag=tf.reshape(OTF_imag,[1,self.size_f,self.size_f])\n",
    "        OTF_real=tf.repeat(OTF_real,16,axis=0)\n",
    "        OTF_imag=tf.repeat(OTF_imag,16,axis=0)\n",
    "        OTF_repeat = tf.complex(OTF_real,OTF_imag)\n",
    "\n",
    "        #multiplication in the spatial frequency domain\n",
    "        x = tf.multiply(x,OTF_repeat)\n",
    "        \n",
    "        #IFFT\n",
    "        x=tf.signal.fftshift(x)\n",
    "        x=tf.signal.ifft2d(x)\n",
    "        x=tf.signal.fftshift(x)\n",
    "\n",
    "        return x,OTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial learning rate\n",
    "initial_learning_rate = 1e-2\n",
    "\n",
    "# Set attenuation steps and attenuation rate\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.95\n",
    "\n",
    "# Create learning rate decay strategy\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate)\n",
    "\n",
    "# Create optimizer instance\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model_P1 = ACNN()\n",
    "model_P1.build((None, 28, 28, 3))\n",
    "model_P1.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# dataset import\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Define noise factor\n",
    "noise_factor = 0.04\n",
    "\n",
    "# Add Gaussian noise\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "# Ensure data is between 0 and 1\n",
    "x_train = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "def augment(images, labels, x1=0.01, x2=0.1, x3=0.05):\n",
    "    # Random rotation\n",
    "    rotation_layer = tf.keras.layers.experimental.preprocessing.RandomRotation(factor=(-x1, x1), fill_mode='reflect', interpolation='bilinear')\n",
    "    images = rotation_layer(images)\n",
    "    \n",
    "    # Random zoom\n",
    "    zoom_layer = tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=(-x2, x2), width_factor=(-x2, x2), fill_mode='reflect', interpolation='bilinear')\n",
    "    images = zoom_layer(images)\n",
    "    \n",
    "    # Random horizontal and vertical translation\n",
    "    translation_layer = tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=(-x3, x3), width_factor=(-x3, x3), fill_mode='reflect', interpolation='bilinear')\n",
    "    images = translation_layer(images)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Create dataset and set batch size\n",
    "BATCH_SIZE = 16\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.map(augment).shuffle(10000).batch(BATCH_SIZE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')  # Create CSVLogger object, logs will be saved to a file named 'training.log'\n",
    "\n",
    "class SaveBestModelVariables(Callback):\n",
    "    def __init__(self, filepath, monitor='val_accuracy', mode='max'):\n",
    "        super(SaveBestModelVariables, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.best = -float('inf') if mode == 'max' else float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is not None:\n",
    "            if (self.mode == 'max' and current > self.best) or (self.mode == 'min' and current < self.best):\n",
    "                self.best = current\n",
    "                trainable_variables = self.model.trainable_variables\n",
    "                # Set font and font size设置字体和字号\n",
    "                plt.rcParams['font.family'] = 'Arial'\n",
    "                plt.rcParams['font.size'] = 20  \n",
    "\n",
    "                # Use the model to make predictions\n",
    "                y_pred = model_P1.predict(x_test, batch_size=16)\n",
    "\n",
    "                # Convert prediction results to class labels\n",
    "                y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "                # Calculate confusion matrix\n",
    "                confusion_mtx = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "                # Plot confusion matrix using seaborn\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap=plt.cm.Blues) \n",
    "                plt.xlabel('Predicted label')\n",
    "                plt.ylabel('True label')\n",
    "\n",
    "                # Save the image\n",
    "                plt.savefig('confusion_matrix_cifar10_all.pdf')\n",
    "                with open(self.filepath, 'wb') as f:\n",
    "                    pickle.dump(trainable_variables, f)\n",
    "                print(f\"Epoch {epoch + 1}: {self.monitor} improved to {current}, saving model variables to {self.filepath}\")\n",
    "\n",
    "# Create custom callback function\n",
    "save_best_model_variables = SaveBestModelVariables(filepath='best_model_variables.pkl', monitor='val_accuracy', mode='max')\n",
    "\n",
    "#training without data qugumation\n",
    "model_P1.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=40, batch_size=16, callbacks=[csv_logger, save_best_model_variables])\n",
    "#training with data qugumation\n",
    "#model_P1.fit(train_ds, validation_data=test_ds,epochs=40, batch_size=16, callbacks=[csv_logger, save_best_model_variables])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
